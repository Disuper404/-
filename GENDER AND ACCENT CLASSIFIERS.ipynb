{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5318bd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-20T16:38:21.169141Z",
     "iopub.status.busy": "2023-04-20T16:38:21.168353Z",
     "iopub.status.idle": "2023-04-20T16:38:25.362658Z",
     "shell.execute_reply": "2023-04-20T16:38:25.361183Z"
    },
    "papermill": {
     "duration": 4.204422,
     "end_time": "2023-04-20T16:38:25.366090",
     "exception": false,
     "start_time": "2023-04-20T16:38:21.161668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d1ef7",
   "metadata": {
    "papermill": {
     "duration": 0.003512,
     "end_time": "2023-04-20T16:38:25.373667",
     "exception": false,
     "start_time": "2023-04-20T16:38:25.370155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. DATA PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d575b57",
   "metadata": {
    "papermill": {
     "duration": 0.003475,
     "end_time": "2023-04-20T16:38:25.380982",
     "exception": false,
     "start_time": "2023-04-20T16:38:25.377507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.1 READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec1f268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T16:38:25.391519Z",
     "iopub.status.busy": "2023-04-20T16:38:25.390764Z",
     "iopub.status.idle": "2023-04-20T16:38:26.493305Z",
     "shell.execute_reply": "2023-04-20T16:38:26.491957Z"
    },
    "papermill": {
     "duration": 1.111762,
     "end_time": "2023-04-20T16:38:26.496628",
     "exception": false,
     "start_time": "2023-04-20T16:38:25.384866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_df = pd.read_csv(\"../input/common-voice/cv-valid-train.csv\")\n",
    "train_df.head()\n",
    "\n",
    "# Filter rows with missing gender or accent\n",
    "train_filter_df = train_df[train_df[\"gender\"].notnull()]\n",
    "train_filter_df = train_filter_df[train_filter_df[\"accent\"].notnull()]\n",
    "\n",
    "def gender_to_labels(gender):\n",
    "    \"\"\"\n",
    "    Convert gender to one-hot label.\n",
    "    Args:\n",
    "        gender (str): Gender in string format.\n",
    "\n",
    "    Returns:\n",
    "        list: One-hot encoded gender label.\n",
    "    \"\"\"\n",
    "    genders = [\"female\", \"male\", \"other\"]\n",
    "    onehot = [0] * len(genders)\n",
    "\n",
    "    if gender in genders:\n",
    "        index = genders.index(gender)\n",
    "        onehot[index] = 1\n",
    "    else:\n",
    "        print(\"Invalid gender:\", gender)\n",
    "\n",
    "    return onehot\n",
    "\n",
    "def accent_to_onehot(accent):\n",
    "    \"\"\"\n",
    "    Convert accent to one-hot label.\n",
    "    Args:\n",
    "        accent (str): Accent in string format.\n",
    "\n",
    "    Returns:\n",
    "        list: One-hot encoded accent label.\n",
    "    \"\"\"\n",
    "    accents = [\"us\", \"australia\", \"england\", \"canada\", \"philippines\", \"ireland\", \"hongkong\", \"indian\", \"malaysia\", \"newzealand\", \"scotland\", \"singapore\", \"southatlandtic\", \"african\", \"wales\", \"bermuda\"]\n",
    "    onehot = [0] * len(accents)\n",
    "    index = accents.index(accent)\n",
    "    onehot[index] = 1\n",
    "\n",
    "    return onehot\n",
    "\n",
    "# Apply gender and accent conversion to labels\n",
    "train_filter_df[\"gender_label\"] = train_filter_df['gender'].apply(gender_to_labels)\n",
    "train_filter_df[\"accent_label\"] = train_filter_df['accent'].apply(accent_to_onehot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e6e9f",
   "metadata": {
    "papermill": {
     "duration": 0.003462,
     "end_time": "2023-04-20T16:38:26.504199",
     "exception": false,
     "start_time": "2023-04-20T16:38:26.500737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.2 CONVERT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f8d819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T16:38:26.513991Z",
     "iopub.status.busy": "2023-04-20T16:38:26.513378Z",
     "iopub.status.idle": "2023-04-20T16:38:54.921651Z",
     "shell.execute_reply": "2023-04-20T16:38:54.920037Z"
    },
    "papermill": {
     "duration": 28.416576,
     "end_time": "2023-04-20T16:38:54.924510",
     "exception": false,
     "start_time": "2023-04-20T16:38:26.507934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# Limit dataset size\n",
    "train_filter_df = train_filter_df.head(1200)\n",
    "\n",
    "# Set dataset path and target properties\n",
    "DATASET_PATH = \"/kaggle/input/common-voice/cv-valid-train/\"\n",
    "target_sample_rate = 16000\n",
    "target_length = 160000\n",
    "\n",
    "def pad_or_trim(waveform, target_length):\n",
    "    \"\"\"\n",
    "    Pad or trim a waveform to the target length.\n",
    "    Args:\n",
    "        waveform (torch.Tensor): Input waveform.\n",
    "        target_length (int): Desired length of the output waveform.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Padded or trimmed waveform.\n",
    "    \"\"\"\n",
    "    length = waveform.shape[1]\n",
    "    \n",
    "    if length > target_length:\n",
    "        waveform = waveform[:, :target_length]\n",
    "    elif length < target_length:\n",
    "        padding = torch.zeros(waveform.shape[0], target_length - length)\n",
    "        waveform = torch.cat((waveform, padding), dim=1)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "# Initialize arrays for audio, gender labels, and accent labels\n",
    "all_audio = []\n",
    "all_gender_labels = []\n",
    "all_accent_labels = []\n",
    "\n",
    "# Process each row in the filtered dataframe\n",
    "for index, row in train_filter_df.iterrows():\n",
    "    audio_path = os.path.join(DATASET_PATH, row['filename'])\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # Pad or trim waveform to target length\n",
    "    waveform = pad_or_trim(waveform, target_length)\n",
    "\n",
    "    all_audio.append(waveform)\n",
    "    all_gender_labels.append(row['gender_label'])\n",
    "    all_accent_labels.append(row['accent_label'])\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "inputs = np.array(all_audio)\n",
    "inputs_gender_labels = np.array(all_gender_labels)\n",
    "inputs_accent_labels = np.array(all_accent_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd150b",
   "metadata": {
    "papermill": {
     "duration": 0.003508,
     "end_time": "2023-04-20T16:38:54.932036",
     "exception": false,
     "start_time": "2023-04-20T16:38:54.928528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.3 SPLIT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2809a382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T16:38:54.942598Z",
     "iopub.status.busy": "2023-04-20T16:38:54.941460Z",
     "iopub.status.idle": "2023-04-20T16:39:17.775566Z",
     "shell.execute_reply": "2023-04-20T16:39:17.774356Z"
    },
    "papermill": {
     "duration": 22.842698,
     "end_time": "2023-04-20T16:39:17.778586",
     "exception": false,
     "start_time": "2023-04-20T16:38:54.935888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, inputs, gender_labels, accent_labels):\n",
    "        self.inputs = inputs\n",
    "        self.gender_labels = gender_labels\n",
    "        self.accent_labels = accent_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.gender_labels[idx], self.accent_labels[idx]\n",
    "\n",
    "# Prepare the data for training\n",
    "# Convert NumPy arrays to float32\n",
    "inputs = [audio_input.numpy().astype(np.float32) for audio_input in inputs]\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "inputs = torch.tensor(inputs)\n",
    "inputs_gender_labels = torch.tensor(inputs_gender_labels, dtype=torch.float32)\n",
    "inputs_accent_labels = torch.tensor(inputs_accent_labels, dtype=torch.float32)\n",
    "\n",
    "# Split the dataset\n",
    "train_inputs, val_inputs, train_gender_labels, val_gender_labels, train_accent_labels, val_accent_labels = train_test_split(\n",
    "    inputs, inputs_gender_labels, inputs_accent_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = AudioDataset(train_inputs, train_gender_labels, train_accent_labels)\n",
    "val_dataset = AudioDataset(val_inputs, val_gender_labels, val_accent_labels)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd966d",
   "metadata": {
    "papermill": {
     "duration": 0.003689,
     "end_time": "2023-04-20T16:39:17.786636",
     "exception": false,
     "start_time": "2023-04-20T16:39:17.782947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. RNN-GENDER CLASSIFIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0a7712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T16:39:17.796726Z",
     "iopub.status.busy": "2023-04-20T16:39:17.796257Z",
     "iopub.status.idle": "2023-04-20T16:40:20.990908Z",
     "shell.execute_reply": "2023-04-20T16:40:20.989498Z"
    },
    "papermill": {
     "duration": 63.207481,
     "end_time": "2023-04-20T16:40:20.998072",
     "exception": false,
     "start_time": "2023-04-20T16:39:17.790591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.9264\n",
      "Epoch [2/20], Loss: 0.2022\n",
      "Epoch [3/20], Loss: 0.0895\n",
      "Epoch [4/20], Loss: 0.0121\n",
      "Epoch [5/20], Loss: 0.0105\n",
      "Epoch [6/20], Loss: 0.0032\n",
      "Epoch [7/20], Loss: 0.0050\n",
      "Epoch [8/20], Loss: 0.0070\n",
      "Epoch [9/20], Loss: 0.0067\n",
      "Epoch [10/20], Loss: 0.0015\n",
      "Epoch [11/20], Loss: 0.0042\n",
      "Epoch [12/20], Loss: 0.0021\n",
      "Epoch [13/20], Loss: 0.0016\n",
      "Epoch [14/20], Loss: 0.0022\n",
      "Epoch [15/20], Loss: 0.0062\n",
      "Epoch [16/20], Loss: 0.0015\n",
      "Epoch [17/20], Loss: 0.0010\n",
      "Epoch [18/20], Loss: 0.0015\n",
      "Epoch [19/20], Loss: 0.0013\n",
      "Epoch [20/20], Loss: 0.0014\n",
      "Test Accuracy: 59.166666666666664%\n"
     ]
    }
   ],
   "source": [
    "# Define the RNN model for gender recognition\n",
    "class GenderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GenderRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through RNN layers\n",
    "        out, _ = self.rnn(x)\n",
    "        \n",
    "        # Pass the output of the last RNN layer through a fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 160000\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = len(train_dataset[0][1])  # Number of gender labels\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the RNN model, loss function and optimizer\n",
    "model = GenderRNN(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (audio, gender_labels, _) in enumerate(train_dataloader):\n",
    "        # Forward pass\n",
    "        outputs = model(audio)\n",
    "        loss = criterion(outputs, torch.max(gender_labels, 1)[1])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for audio, gender_labels, _ in val_dataloader:\n",
    "        outputs = model(audio)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += gender_labels.size(0)\n",
    "        correct += (predicted == torch.max(gender_labels, 1)[1]).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d52381",
   "metadata": {
    "papermill": {
     "duration": 0.004772,
     "end_time": "2023-04-20T16:40:21.007970",
     "exception": false,
     "start_time": "2023-04-20T16:40:21.003198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. 1DCNN-GENDER AND ACCENT CLASSIFIER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bca370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T16:40:21.020621Z",
     "iopub.status.busy": "2023-04-20T16:40:21.019985Z",
     "iopub.status.idle": "2023-04-20T16:51:19.266693Z",
     "shell.execute_reply": "2023-04-20T16:51:19.264792Z"
    },
    "papermill": {
     "duration": 658.25747,
     "end_time": "2023-04-20T16:51:19.270595",
     "exception": false,
     "start_time": "2023-04-20T16:40:21.013125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:29<00:00,  6.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 10.685899114608764\n",
      "Validation Accuracy (Gender): 77.08%\n",
      "Validation Accuracy (Accent): 25.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:19<00:00,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.2978541294733685\n",
      "Validation Accuracy (Gender): 77.08%\n",
      "Validation Accuracy (Accent): 32.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:20<00:00,  6.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.9255502303441365\n",
      "Validation Accuracy (Gender): 77.08%\n",
      "Validation Accuracy (Accent): 37.08%\n"
     ]
    }
   ],
   "source": [
    "class Simple1DCNN(nn.Module):\n",
    "    def __init__(self, input_length, num_classes_gender, num_classes_accent):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Calculate the length of the fully connected layer input\n",
    "        self.fc_length = input_length // (2**3)\n",
    "        \n",
    "        # Define fully connected layers for gender and accent classification\n",
    "        self.fc_gender = nn.Linear(64 * self.fc_length, num_classes_gender)\n",
    "        self.fc_accent = nn.Linear(64 * self.fc_length, num_classes_accent)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through convolutional and pooling layers\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass the output through fully connected layers for gender and accent\n",
    "        out_gender = self.fc_gender(x)\n",
    "        out_accent = self.fc_accent(x)\n",
    "\n",
    "        return out_gender, out_accent\n",
    "\n",
    "# Model initialization\n",
    "input_length = 160000\n",
    "num_classes_gender = 3\n",
    "num_classes_accent = 16\n",
    "model = Simple1DCNN(input_length, num_classes_gender, num_classes_accent)\n",
    "\n",
    "# Set device for the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, gender_labels, accent_labels in tqdm(train_dataloader):\n",
    "        # Move inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        gender_labels = torch.argmax(gender_labels, dim=1).to(device)\n",
    "        accent_labels = torch.argmax(accent_labels, dim=1).to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out_gender, out_accent = model(inputs)\n",
    "        loss_gender = criterion(out_gender, gender_labels)\n",
    "        loss_accent = criterion(out_accent, accent_labels)\n",
    "        \n",
    "        # Calculate total loss and backpropagate\n",
    "        loss = loss_gender + loss_accent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print loss for the current epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_dataloader)}\")\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        gender_correct = 0\n",
    "        accent_correct = 0\n",
    "        total = 0\n",
    "        for inputs, gender_labels, accent_labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            gender_labels = gender_labels.to(device)\n",
    "            accent_labels = accent_labels.to(device)\n",
    "            \n",
    "            out_gender, out_accent = model(inputs)\n",
    "            _, gender_predicted = torch.max(out_gender, 1)\n",
    "            _, accent_predicted = torch.max(out_accent, 1)\n",
    "            \n",
    "            gender_labels = torch.argmax(gender_labels, dim=1)\n",
    "            accent_labels = torch.argmax(accent_labels, dim=1)\n",
    "            gender_correct += (gender_predicted == gender_labels).sum().item()\n",
    "            accent_correct += (accent_predicted == accent_labels).sum().item()\n",
    "            total += gender_labels.size(0)\n",
    "        \n",
    "        print(f\"Validation Accuracy (Gender): {gender_correct/total * 100:.2f}%\")\n",
    "        print(f\"Validation Accuracy (Accent): {accent_correct/total * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 790.228701,
   "end_time": "2023-04-20T16:51:20.715215",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-20T16:38:10.486514",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
